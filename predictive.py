# -*- coding: utf-8 -*-
"""Predictive.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fB3HJWHV1Kf73fPHj7AimDUsHdt8OEO8
"""

# Memuat library yang akan digunakan dalam project ini
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

from sklearn.linear_model import LinearRegression, ElasticNet
from sklearn.svm import SVR
from sklearn.neural_network import MLPRegressor
from sklearn.multioutput import MultiOutputRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_squared_error

"""# **Data Loading**
Data berisi lebih dari 16.000 pertandingan sepakbola dari 5 liga top Eropa (Inggris, Spanyol, Jerman, Italia, Prancis) serta Liga Champions dan Liga Europa dalam 7-10 musim terakhir, dari musim 2015-2016 hingga 2024-2025.

Di dalam setiap baris terdapat 53 kolom berisi statistik tiap pertandingan, dari tim yang bertanding beserta skornya, hingga detail seperti jumlah penguasaan bola, umpan, penyelamatan, dll.
"""

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/My Drive/Dicoding ML Terapan/Pertama/matches.csv')
df.head()

df.shape

df.info()

"""Untuk melengkapi data tiap pertandingan yang sudah ada, dilakukan proses pembuatan kolom baru dari kolom yang sudah ada untuk menghasilkan data baru"""

# Membuat kolom persentase tembakan akurat
df['H_shots_percentage'] = round(df['H_shots_on_target'] / df['A_shots_total'] * 100)
df['A_shots_percentage'] = round(df['A_shots_on_target'] / df['A_shots_total'] * 100)

# Membuat kolom persentase penyelamatan
df['H_saves_percentage'] = round(df['H_saves'] / df['A_shots_on_target'] * 100)
df['A_saves_percentage'] = round(df['A_saves'] / df['H_shots_on_target'] * 100)

# Membuat kolom persentase umpan akurat
df['H_passes_percentage'] = round(df['H_passes_completed'] / df['H_passes_total'] * 100)
df['A_passes_percentage'] = round(df['A_passes_completed'] / df['A_passes_total'] * 100)

# Membuat kolom perbedaan gol
# df['goal_diff'] = df['H_goals'] - df['A_goals']

"""# **Exploratory Data Analysis**

**Missing value**

Pengecekan data kosong menunjukkan terdapat data kosong, namun hanya pada kolom persentase. Ini bisa  terjadi karena kesalahan pembagian. Sehingga kekosongan ini bisa diisi dengan angka 0.

Kesalahan pembagian juga mengakibatkan adanya nilai tak hingga (inf). Untuk mengatasi hal ini juga akan dilakukan cara yang sama, yaitu menggantinya dengan 0.

Selain itu juga dilakukan penghapusan data duplikat untuk memastikan setiap baris unik.
"""

missings = [np.inf, -np.inf, np.nan, None]
df_null = df.isin(missings).sum()
df_null[df_null > 0]

# Mengisi data kosong dengan 0
df.replace(missings, 0, inplace=True)

# Menghapus baris duplikat
df.drop_duplicates(inplace=True)

df.describe()

def get_winner(row):
  h = row['H_goals']
  a = row['A_goals']

  if h > a:
    return 'Home'
  elif h < a:
    return 'Away'
  else:
    return 'Draw'

df['winner'] = df.apply(get_winner, axis=1)
count = df['winner'].value_counts()
count.plot(kind='bar')

# Memilih data bertipe numerik dari dataframe
num_features = df.select_dtypes(exclude=[object]).columns
# num_features = num_features.drop(['H_goals', 'A_goals', 'goal_diff'])

# Membuat dataframe baru yang hanya berisi data numerik
df_num = df[num_features]
df_num.head()

"""**Outlier**

Penanganan outlier atau data yang jauh dari cakupan umum menggunakan Inter Quartile Range (IQR) Method. Setelah menghapus data outlier, data yang tersisa menjadi sekitar 8.300 baris.
"""

# Menampilkan box plot tiap kolom untuk melihat adanya outlier
plt.figure(figsize=(16, len(num_features) * 4))
for i, feature in enumerate(num_features, 1):
    plt.subplot(len(num_features), 4, i)
    sns.boxplot(x=df_num[feature])

plt.tight_layout()
plt.show()

# Menghapus baris di luar jangkauan kuartil
Q1 = df_num.quantile(0.25)
Q3 = df_num.quantile(0.75)
IQR = Q3 - Q1

df_clean = df_num[~((df_num < (Q1 - 1.5 * IQR)) |(df_num > (Q3 + 1.5 * IQR))).any(axis=1)]
df_clean.shape

"""**Univariate Analysis**

* Sebagian besar dari diagram menunjukkan distribusi normal, yang terlihat dari histogram berbentuk lonceng (bell curve).
* Seluruh data kartu merah dan gol bunuh diri untuk kedua tim bernilai 0. Menunjukkan adanya kartu merah atau gol bunuh diri pada pertandingan jarang terjadi, sehingga data pertandingan yang terdapat kartu merah atau gol bunuh diri adalah outlier.
* Nilai "result" yang bernilai positif agak lebih banyak dari yang bernilai negatif, menunjukkan lebih banyak tim tuan rumah yang menang daripada tim tamu. Ini sejalan dengan anggapan bermain di kandang lebih menguntungkan.
"""

df_clean.hist(bins=50, figsize=(20,15))
plt.show()

"""**Multivariate Analysis**

Untuk mengamati hubungan variabel dengan fitur target "result", digunakan analisis melalui pair plot dan correlation matrix.

* Analisis pair plot menunjukkan beberapa variabel seperti "H_shots_on_target" dan "A_shots_on_target" memiliki korelasi yang ditandai dengan adanya bentuk grafik yang berbentuk agak naik atau turun.
* Setelah menggunakan correlation matrix, dilakukan filtering untuk variabel yang memiliki skor lebih dari 0.15 atau kurang dari -0.15, hasilnya terdapat 11 variabel yang dapat digunakan untuk membangun model.
"""

df_clean = df_clean.drop(columns=['H_red_cards', 'H_own_goals', 'A_red_cards', 'A_own_goals'])
plt.figure(figsize=(40, 32))
correlation_matrix = df_clean.corr().round(2)
sns.heatmap(data=correlation_matrix, cmap='coolwarm', linewidths=0.5, annot=True, fmt='.2f')

"""# **Data Preparation**

Dalam bagian ini dilakukan dua langkah
* Standardisasi, untuk membuat data fitur mendekati distribusi normal, dapat dilihat dari simpangan baku (std) yang mendekati 1 dan rata-rata (mean) mendekati 0.
* Pembagian data training dan testing, dengan rasio 80% data digunakan untuk training dan 20% untuk testing.
"""

threshold = 0.1
col = 'goal_diff'

h_corr = correlation_matrix.loc[abs(correlation_matrix['H_goals']) >= threshold]
a_corr = correlation_matrix.loc[abs(correlation_matrix['A_goals']) >= threshold]

corr_cols = pd.concat([h_corr['H_goals'], a_corr['A_goals']])
corr_cols

cols = list(set(corr_cols.index))
df_prep = df_clean[cols].copy()
df_prep.head()

# Standardisasi fitur
scaler = StandardScaler()
scaled_data = scaler.fit_transform(df_prep)
df_scaled = pd.DataFrame(scaled_data, columns=df_prep.columns)

# Pembagian data training dan testing
col_target = ['H_goals', 'A_goals']
X = df_scaled.drop(col_target, axis=1)
y = df_prep.loc[:, col_target]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 128)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

X_train.describe().round(4)

"""# **Model Development**

Untuk pelatihan model akan menggunakan fungsi Lazy Regressor yang bertujuan untuk membuat banyak model regresi dari berbagai macam algoritma. Setelah pelatihan akan dipilih 5 model terbaik.
"""

models = pd.DataFrame(
    index=['train_mse', 'test_mse'],
    columns=['LR', 'ETR', 'RF', 'SVR']
)

lin = LinearRegression()
lin.fit(X_train, y_train)

ext = ExtraTreesRegressor(random_state=42)
ext.fit(X_train, y_train)

rf = RandomForestRegressor(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

svr = MultiOutputRegressor(SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1))
svr.fit(X_train,y_train)

"""# **Model Evaluation**

Menghitung MSE tiap model pada data training dan testing untuk membandingkan performa model-model ini pada saat training dan testing.

Uji coba perhitungan hasil juga akan dilalukan menggunakan 20 data testing untuk melihat seberapa akurat hasil prediksi model-model terpilih dengan data sebenarnya. Dalam uji coba ditunjukkan hasil prediksi "result" beserta skor pertandingan berdasarkan inverse dari PCA.
"""

mse = pd.DataFrame(columns=['train', 'test'], index=models.columns)
model_dict = {'LR': lin, 'ETR': ext, 'RF': rf, 'SVR': svr}

for name, model in model_dict.items():
    mse.loc[name, 'train'] = round(mean_squared_error(y_true=y_train, y_pred=model.predict(X_train)), 3)
    mse.loc[name, 'test'] = round(mean_squared_error(y_true=y_test, y_pred=model.predict(X_test)), 3)

mse

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

# Menguji model dengan 20 data testing
inf_x = X_test.iloc[:20].copy()
inf_y = y_test[:20]
pred_dict = {'y_true': [f'{y["H_goals"]}-{y["A_goals"]}' for i,y in inf_y.iterrows()]}

for name, model in model_dict.items():
    y_hat = model.predict(inf_x)
    y_inv = [f'{round(y[0], 2)}, {round(y[1], 2)} ({int(round(y[0]))}-{int(round(y[1]))})' for y in y_hat]
    pred_dict[name] = y_inv

pred = pd.DataFrame(pred_dict)
pred.index = inf_y.index
pred